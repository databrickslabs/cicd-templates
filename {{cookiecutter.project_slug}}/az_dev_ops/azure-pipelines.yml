variables:
- group: Databricks-environment

trigger:
  batch: true
  branches:
    include:
    - '*'

  tags:
    include:
      - v*.*
      - prod

  paths:
    exclude:
      - .github/*
      - mlruns/*

stages:
- stage: onPush
  jobs:
  - job: onPushJob
    pool:
      vmImage: 'ubuntu-18.04'

    steps:
    - script: env | sort
      displayName: 'Environment / Context'

    - task: UsePythonVersion@0
      displayName: 'Use Python 3.7'
      inputs:
        versionSpec: 3.7

    - checkout: self
      persistCredentials: true
      clean: true
      displayName: 'Checkout & Build.Reason: $(Build.Reason) & Build.SourceBranchName: $(Build.SourceBranchName)'

    - script: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install deployment/databrickslabs_cicdtemplates-0.2.3-py3-none-any.whl
      displayName: 'Install Python Dependencies'

    - script: |
        pip install pytest
        python -m pytest
      displayName: 'Run Unit tests'

    - script: |
        python setup.py bdist_wheel
      displayName: 'Build artifact'

    - task: riserrad.azdo-databricks.azdo-databricks-configuredatabricks.configuredatabricks@0
      inputs:
        url: '$(DATABRICKS_HOST)'
        token: '$(DATABRICKS_TOKEN)'
      displayName: 'Configure Databricks CLI for AZDO'

    - script: |
        # Prevent the "RestException: RESOURCE_DOES_NOT_EXIST: Parent directory /Users/$(Username)/experiments does not exist" Error first time.
        databricks workspace mkdirs /Users/$(DATABRICKS_USERNAME)/experiments --profile AZDO

        python -c "from databrickslabs_cicdtemplates import dev_cicd_pipeline; dev_cicd_pipeline.main('dev-tests');"
      env:
        DATABRICKS_HOST: $(DATABRICKS_STAGING_HOST)
        DATABRICKS_TOKEN: $(DATABRICKS_STAGING_TOKEN)
        MLFLOW_TRACKING_URI: $(MLFLOW_TRACKING_URI)
        CURRENT_CLOUD: $(CURRENT_CLOUD)
      displayName: 'Deploy artifact'


- stage: onRelease
  dependsOn: [onPush]
  condition: |
    or(
      startsWith(variables['Build.SourceBranch'], 'refs/heads/releases'),
      startsWith(variables['Build.SourceBranch'], 'refs/tags/v')
    )
  jobs:
  - job: onReleaseJob
    pool:
      vmImage: 'ubuntu-18.04'

    steps:
      - script: env | sort
        displayName: 'Environment / Context'

      - task: UsePythonVersion@0
        displayName: 'Use Python 3.7'
        inputs:
          versionSpec: 3.7

      - checkout: self
        persistCredentials: true
        clean: true
        displayName: 'Checkout & Build.Reason: $(Build.Reason) & Build.SourceBranchName: $(Build.SourceBranchName)'

      - script: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install deployment/databrickslabs_cicdtemplates-0.2.3-py3-none-any.whl
        displayName: 'Install Python Dependencies'

      - script: |
          pip install pytest
          python -m pytest
        displayName: 'Run Unit tests'

      - script: |
          python setup.py bdist_wheel
        displayName: 'Build artifact'

      - task: riserrad.azdo-databricks.azdo-databricks-configuredatabricks.configuredatabricks@0
        inputs:
          url: '$(DATABRICKS_STAGING_HOST)'
          token: '$(DATABRICKS_STAGING_TOKEN)'
        displayName: 'Configure Databricks CLI for AZDO'

      - script: |
          # Prevent the "RestException: RESOURCE_DOES_NOT_EXIST: Parent directory /Users/$(Username)/experiments does not exist" Error first time.
          databricks workspace mkdirs /Users/$(DATABRICKS_USERNAME)/experiments --profile AZDO

          python -c "from databrickslabs_cicdtemplates import release_cicd_pipeline; release_cicd_pipeline.main('integration-tests', 'pipelines', True);"
        env:
          DATABRICKS_HOST: $(DATABRICKS_STAGING_HOST)
          DATABRICKS_TOKEN: $(DATABRICKS_STAGING_TOKEN)
          MLFLOW_TRACKING_URI: $(MLFLOW_TRACKING_URI)
          CURRENT_CLOUD: $(CURRENT_CLOUD)
        displayName: 'Deploy artifact'